---
title: "Fourth Blog Post"
---


```{r setup, echo = FALSE}
knitr::opts_chunk$set(fig.path = "../images/")
#knitr::opts_chunk$set(fig.path = "C:/Users/Bridget/OneDrive/R_Scripts/repos/brknapp.github.io/images")

```

```{r render, echo = FALSE, eval = FALSE}
rmarkdown::render("C:/Users/Bridget/OneDrive/R_Scripts/repos/brknapp.github.io/_Rmd/2022-07-21-fourth-blog-post.Rmd",
                  output_format = "github_document",
                  output_dir = "C:/Users/Bridget/OneDrive/R_Scripts/repos/brknapp.github.io/_posts/",
                  output_options = list(html_preview=FALSE) 
)
```

# Modeling

Out of all the methods we have learned, I found regression trees to be the most interesting because they produce graphs that are easy to read. In general, tree-based methods split the predictor space into regions and then formulate predictions based on those regions. The model determines each split by using recursive binary splitting, an algorithm that takes every possible value for each predictor, finds the residual sum of squares (RSS), and minimizes the RSS based off the mean value for each possible split it could do. Regression trees predict a continuous response by using the mean of all the observations in a given predictor space region. 

I grabbed the wine data set from the [Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) and made a regression tree to see if I could predict the amount of alcohol in each wine based on the variables given.



```{r 4_32_7_21_2022,echo=FALSE,warning=FALSE,message=FALSE}
library(tree)
library(readr)
library(tidyverse)
library(class)
library(caret)
library(rpart)
library(rpart.plot)
```

```{r 4_54_7_21_2022,echo=FALSE}
wine_data<-read.csv("C://Users//Bridget//OneDrive//R_Scripts//repos//brknapp.github.io//wine.data")

colnames(wine_data)<-c("category",
                       "Alcohol",
                       "Malic_acid",
                       "Ash",
                       "Alcalinity_of_ash",
                       "Magnesium",
                       "Total_phenols",
                       "Flavanoids",
                       "Nonflavanoid_phenols",
                       "Proanthocyanins",
                       "Color_intensity",
                       "Hue",
                       "OD280_OD315_of_diluted_wines",
                       "Proline") 
```

```{r 4_56_7_21_2022}
head(wine_data)
str(wine_data)
```

```{r 4_55_7_21_2022}
set.seed(dim(wine_data)[1])
train <- sample(1:nrow(wine_data), size = nrow(wine_data)*0.8)
test <- dplyr::setdiff(1:nrow(wine_data), train)
wine_dataTrain <- wine_data[train, ]
wine_dataTest <- wine_data[test, ]
treeFit <- tree(Alcohol ~ ., data = wine_dataTrain)
plot(treeFit); text(treeFit, pretty = 0, cex = 0.6)
#cross-validation:
#$dev is the cross-validation error (we want to minimize this)
cvTree <- cv.tree(treeFit); cvTree
#predict:
pred <- predict(treeFit, newdata = dplyr::select(wine_dataTest, -Alcohol))
#Calculate Root MSE
sqrt(mean((pred-wine_dataTest$Alcohol)^2))
```